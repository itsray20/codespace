{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: reportlab in /usr/local/python/3.10.8/lib/python3.10/site-packages (4.0.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/codespace/.local/lib/python3.10/site-packages (from reportlab) (10.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF report generated as 'website_analysis_report.pdf'.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "import matplotlib.pyplot as plt\n",
    "import pdfkit\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib import colors  # Import the 'colors' module\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Function to fetch content from a URL\n",
    "def fetch_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"Failed to fetch content from {url}. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while fetching content: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract and preprocess content from HTML\n",
    "def extract_and_preprocess_content(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    content = ' '.join([p.get_text() for p in paragraphs])\n",
    "    return content\n",
    "\n",
    "# Function to preprocess text, tokenize, and create a frequency table\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Initialize a stop words set\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Create a frequency distribution\n",
    "    fdist = FreqDist(words)\n",
    "\n",
    "    return fdist\n",
    "\n",
    "# Function to generate a PDF report\n",
    "def generate_pdf_report(website_url, content, keyword_frequency):\n",
    "    pdf_buffer = BytesIO()\n",
    "    doc = SimpleDocTemplate(pdf_buffer, pagesize=letter)\n",
    "\n",
    "    elements = []\n",
    "\n",
    "    # Title\n",
    "    title = Paragraph(\"Website Analysis Report\", getSampleStyleSheet()['Title'])\n",
    "    elements.append(title)\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # URL\n",
    "    url_paragraph = Paragraph(f\"URL: {website_url}\", getSampleStyleSheet()['Normal'])\n",
    "    elements.append(url_paragraph)\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Content Analysis\n",
    "    content_analysis = Paragraph(\"Content Analysis:\", getSampleStyleSheet()['Heading2'])\n",
    "    elements.append(content_analysis)\n",
    "    elements.append(Spacer(1, 6))\n",
    "\n",
    "    # Keywords Frequency Table (simplified)\n",
    "    keyword_table_data = []\n",
    "    for word, freq in keyword_frequency.items():\n",
    "        keyword_table_data.append([word, freq])\n",
    "\n",
    "    keyword_table_style = [\n",
    "        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "        ('ALIGN', (1, 1), (-1, -1), 'RIGHT'),\n",
    "    ]\n",
    "    keyword_table = Table(keyword_table_data, colWidths=[200, 100], style=keyword_table_style)\n",
    "    elements.append(keyword_table)\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    # Save PDF\n",
    "    doc.build(elements)\n",
    "\n",
    "    # Save the PDF to a file\n",
    "    pdf_filename = 'website_analysis_report.pdf'\n",
    "    with open(pdf_filename, 'wb') as pdf_file:\n",
    "        pdf_file.write(pdf_buffer.getvalue())\n",
    "\n",
    "    print(f\"PDF report generated as '{pdf_filename}'.\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    website_url = 'https://medium.com/dataflair/these-projects-will-make-you-the-superhero-of-python-city-14101e62393b'  # Replace with the target website URL\n",
    "    content = fetch_content(website_url)\n",
    "\n",
    "    if content:\n",
    "        # Extract and preprocess content\n",
    "        article_content = extract_and_preprocess_content(content)\n",
    "\n",
    "        # Tokenize sentences\n",
    "        sentences = sent_tokenize(article_content)\n",
    "\n",
    "        # Preprocess text and create a frequency table\n",
    "        keyword_frequency = preprocess_text(article_content)\n",
    "\n",
    "        # Generate PDF report\n",
    "        generate_pdf_report(website_url, content, keyword_frequency)\n",
    "    else:\n",
    "        print(\"Failed to fetch content from the URL.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
